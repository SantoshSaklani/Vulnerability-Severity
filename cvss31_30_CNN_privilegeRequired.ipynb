{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBgijsZig+K5sw6KoF7a8r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SantoshSaklani/Vulnerability-Severity/blob/main/cvss31_30_CNN_privilegeRequired.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3meZad65wtPO"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cKxOEQ8D1q7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "file_path = '/content/drive/My Drive/cvssV30_31_metricFinalDataset.csv'\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urlK4dThw4lP",
        "outputId": "3c69ba3e-f98f-4f51-e2b8-f86f01adb047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Now you can work with the DataFrame 'df'\n",
        "print(df.head())  # Print the first few rows of the DataFrame"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QP6jSj-0-c0",
        "outputId": "bda46b4f-d317-4302-88fe-243f87e56fa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0                                       descriptions attackVector  \\\n",
            "0           0  ScriptAlias directory in NCSA and Apache httpd...      NETWORK   \n",
            "1           1  Cross-site scripting (XSS) vulnerability in th...      NETWORK   \n",
            "2           2  El protocolo DNS, como es implementado en (1) ...      NETWORK   \n",
            "3           3  El núcleo de Linux anterior a 2.6.25.10, no re...        LOCAL   \n",
            "4           4  La función do_change_type en fs/namespace.c de...        LOCAL   \n",
            "\n",
            "  attackComplexity privilegesRequired userInteraction      scope  \\\n",
            "0              LOW               NONE            NONE  UNCHANGED   \n",
            "1              LOW               HIGH        REQUIRED    CHANGED   \n",
            "2             HIGH               NONE            NONE    CHANGED   \n",
            "3              LOW                LOW            NONE  UNCHANGED   \n",
            "4              LOW                LOW            NONE  UNCHANGED   \n",
            "\n",
            "  confidentialityImpact integrityImpact availabilityImpact  baseScore  \\\n",
            "0                  HIGH            NONE               NONE        7.5   \n",
            "1                   LOW             LOW               NONE        4.8   \n",
            "2                  NONE            HIGH               NONE        6.8   \n",
            "3                  HIGH            HIGH               HIGH        7.8   \n",
            "4                  HIGH            HIGH               HIGH        7.8   \n",
            "\n",
            "  baseSeverity  exploitabilityScore  impactScore  \n",
            "0         HIGH                  3.9          3.6  \n",
            "1       MEDIUM                  1.7          2.7  \n",
            "2       MEDIUM                  2.2          4.0  \n",
            "3         HIGH                  1.8          5.9  \n",
            "4         HIGH                  1.8          5.9  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop unnamed column\n",
        "df = df.drop(columns=df.columns[df.columns.str.contains('Unnamed:')])\n",
        "\n",
        "print(\"DataFrame after dropping unnamed column:\")\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9KNTAYi1scQ",
        "outputId": "caa7c943-fb44-4acd-ac94-b6f9a679f822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame after dropping unnamed column:\n",
            "                                             descriptions      attackVector  \\\n",
            "0       ScriptAlias directory in NCSA and Apache httpd...           NETWORK   \n",
            "1       Cross-site scripting (XSS) vulnerability in th...           NETWORK   \n",
            "2       El protocolo DNS, como es implementado en (1) ...           NETWORK   \n",
            "3       El núcleo de Linux anterior a 2.6.25.10, no re...             LOCAL   \n",
            "4       La función do_change_type en fs/namespace.c de...             LOCAL   \n",
            "...                                                   ...               ...   \n",
            "133423  A vulnerability classified as critical was fou...           NETWORK   \n",
            "133424  A vulnerability, which was classified as probl...  ADJACENT_NETWORK   \n",
            "133425  Desbordamiento de búfer de pila en el reposito...             LOCAL   \n",
            "133426  Cross-site Scripting (XSS) - Stored in GitHub ...           NETWORK   \n",
            "133427  Cross-site Scripting (XSS) - DOM in GitHub rep...           NETWORK   \n",
            "\n",
            "       attackComplexity privilegesRequired userInteraction      scope  \\\n",
            "0                   LOW               NONE            NONE  UNCHANGED   \n",
            "1                   LOW               HIGH        REQUIRED    CHANGED   \n",
            "2                  HIGH               NONE            NONE    CHANGED   \n",
            "3                   LOW                LOW            NONE  UNCHANGED   \n",
            "4                   LOW                LOW            NONE  UNCHANGED   \n",
            "...                 ...                ...             ...        ...   \n",
            "133423              LOW                LOW            NONE  UNCHANGED   \n",
            "133424              LOW                LOW            NONE  UNCHANGED   \n",
            "133425              LOW               NONE            NONE  UNCHANGED   \n",
            "133426              LOW               NONE        REQUIRED  UNCHANGED   \n",
            "133427              LOW               NONE        REQUIRED  UNCHANGED   \n",
            "\n",
            "       confidentialityImpact integrityImpact availabilityImpact  baseScore  \\\n",
            "0                       HIGH            NONE               NONE        7.5   \n",
            "1                        LOW             LOW               NONE        4.8   \n",
            "2                       NONE            HIGH               NONE        6.8   \n",
            "3                       HIGH            HIGH               HIGH        7.8   \n",
            "4                       HIGH            HIGH               HIGH        7.8   \n",
            "...                      ...             ...                ...        ...   \n",
            "133423                   LOW             LOW                LOW        6.3   \n",
            "133424                   LOW             LOW                LOW        5.5   \n",
            "133425                  NONE             LOW                LOW        5.1   \n",
            "133426                   LOW             LOW               HIGH        7.6   \n",
            "133427                  HIGH             LOW                LOW        7.6   \n",
            "\n",
            "       baseSeverity  exploitabilityScore  impactScore  \n",
            "0              HIGH                  3.9          3.6  \n",
            "1            MEDIUM                  1.7          2.7  \n",
            "2            MEDIUM                  2.2          4.0  \n",
            "3              HIGH                  1.8          5.9  \n",
            "4              HIGH                  1.8          5.9  \n",
            "...             ...                  ...          ...  \n",
            "133423       MEDIUM                  2.8          3.4  \n",
            "133424       MEDIUM                  2.1          3.4  \n",
            "133425       MEDIUM                  2.5          2.5  \n",
            "133426         HIGH                  2.8          4.7  \n",
            "133427         HIGH                  2.8          4.7  \n",
            "\n",
            "[133428 rows x 13 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your DataFrame is named new_df\n",
        "column_value_counts = {}\n",
        "for column in df.columns:\n",
        "    if column != 'descriptions':  # Exclude the 'descriptions' column\n",
        "        column_value_counts[column] = df[column].value_counts()\n",
        "\n",
        "# Print the counts for each column (excluding 'descriptions')\n",
        "for column, counts in column_value_counts.items():\n",
        "    print(f\"Counts for '{column}':\\n{counts}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a7YSyO114Dw",
        "outputId": "13ff589e-db14-442c-d8ab-141f004d53a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counts for 'attackVector':\n",
            "NETWORK             96612\n",
            "LOCAL               31677\n",
            "ADJACENT_NETWORK     3646\n",
            "PHYSICAL             1493\n",
            "Name: attackVector, dtype: int64\n",
            "\n",
            "Counts for 'attackComplexity':\n",
            "LOW     120988\n",
            "HIGH     12440\n",
            "Name: attackComplexity, dtype: int64\n",
            "\n",
            "Counts for 'privilegesRequired':\n",
            "NONE    82870\n",
            "LOW     38947\n",
            "HIGH    11611\n",
            "Name: privilegesRequired, dtype: int64\n",
            "\n",
            "Counts for 'userInteraction':\n",
            "NONE        86449\n",
            "REQUIRED    46979\n",
            "Name: userInteraction, dtype: int64\n",
            "\n",
            "Counts for 'scope':\n",
            "UNCHANGED    108378\n",
            "CHANGED       25050\n",
            "Name: scope, dtype: int64\n",
            "\n",
            "Counts for 'confidentialityImpact':\n",
            "HIGH    74579\n",
            "NONE    30079\n",
            "LOW     28770\n",
            "Name: confidentialityImpact, dtype: int64\n",
            "\n",
            "Counts for 'integrityImpact':\n",
            "HIGH    64463\n",
            "NONE    41412\n",
            "LOW     27553\n",
            "Name: integrityImpact, dtype: int64\n",
            "\n",
            "Counts for 'availabilityImpact':\n",
            "HIGH    73893\n",
            "NONE    52075\n",
            "LOW      7460\n",
            "Name: availabilityImpact, dtype: int64\n",
            "\n",
            "Counts for 'baseScore':\n",
            "9.8    15861\n",
            "7.5    15340\n",
            "7.8    13372\n",
            "8.8    12037\n",
            "6.5     9125\n",
            "       ...  \n",
            "1.8       14\n",
            "2.1       14\n",
            "1.6        3\n",
            "1.7        1\n",
            "9.2        1\n",
            "Name: baseScore, Length: 84, dtype: int64\n",
            "\n",
            "Counts for 'baseSeverity':\n",
            "MEDIUM      55785\n",
            "HIGH        54214\n",
            "CRITICAL    19401\n",
            "LOW          4010\n",
            "NONE           18\n",
            "Name: baseSeverity, dtype: int64\n",
            "\n",
            "Counts for 'exploitabilityScore':\n",
            "3.9    37947\n",
            "2.8    36729\n",
            "1.8    23263\n",
            "2.3     6136\n",
            "2.2     4631\n",
            "1.2     4565\n",
            "1.6     2955\n",
            "0.8     2559\n",
            "1.7     2187\n",
            "2.1     2062\n",
            "1.0     1842\n",
            "0.9     1588\n",
            "2.5     1335\n",
            "3.1     1202\n",
            "1.3      924\n",
            "2.0      833\n",
            "1.5      574\n",
            "0.5      570\n",
            "0.7      477\n",
            "1.1      289\n",
            "1.4      267\n",
            "0.6      201\n",
            "0.3      156\n",
            "0.4       86\n",
            "0.2       34\n",
            "0.1       16\n",
            "Name: exploitabilityScore, dtype: int64\n",
            "\n",
            "Counts for 'impactScore':\n",
            "5.9    50546\n",
            "3.6    34832\n",
            "2.7    15916\n",
            "1.4    12172\n",
            "5.2     4088\n",
            "6.0     3720\n",
            "3.4     2628\n",
            "2.5     2421\n",
            "4.0     2250\n",
            "4.7     1379\n",
            "4.2     1303\n",
            "3.7      822\n",
            "5.8      583\n",
            "5.5      495\n",
            "5.3      255\n",
            "0.0       18\n",
            "Name: impactScore, dtype: int64\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your DataFrame (replace this with your actual code to load data)\n",
        "# new_df2 = pd.read_csv(\"your_data.csv\")\n",
        "\n",
        "# Choose the metric you want to analyze (e.g., 'attackVector')\n",
        "selected_metric = 'attackVector'\n",
        "\n",
        "# Calculate class distribution\n",
        "class_counts = df[selected_metric].value_counts()\n",
        "\n",
        "# Calculate the percentage of samples in each class\n",
        "class_percentages = class_counts / class_counts.sum() * 100\n",
        "\n",
        "# Identify imbalanced classes based on a threshold (e.g., 10%)\n",
        "imbalanced_threshold = 10\n",
        "imbalanced_classes = class_percentages[class_percentages < imbalanced_threshold]\n",
        "\n",
        "# Print imbalanced classes\n",
        "print(\"Imbalanced Classes:\")\n",
        "print(imbalanced_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7EL4n3J14Ph",
        "outputId": "4183e89c-3d7b-4fc6-958f-3b12791d7526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imbalanced Classes:\n",
            "ADJACENT_NETWORK    2.732560\n",
            "PHYSICAL            1.118956\n",
            "Name: attackVector, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your DataFrame (replace this with your actual code to load data)\n",
        "# new_df2 = pd.read_csv(\"your_data.csv\")\n",
        "\n",
        "# Choose the metric you want to analyze (e.g., 'attackVector')\n",
        "selected_metric = 'attackComplexity'\n",
        "\n",
        "# Calculate class distribution\n",
        "class_counts = df[selected_metric].value_counts()\n",
        "\n",
        "# Calculate the percentage of samples in each class\n",
        "class_percentages = class_counts / class_counts.sum() * 100\n",
        "\n",
        "# Identify imbalanced classes based on a threshold (e.g., 10%)\n",
        "imbalanced_threshold = 10\n",
        "imbalanced_classes = class_percentages[class_percentages < imbalanced_threshold]\n",
        "\n",
        "# Print imbalanced classes\n",
        "print(\"Imbalanced Classes:\")\n",
        "print(imbalanced_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3rlePZz14aI",
        "outputId": "231d7103-5dc9-4383-8c7d-470ad69c3567"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imbalanced Classes:\n",
            "HIGH    9.32338\n",
            "Name: attackComplexity, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your DataFrame (replace this with your actual code to load data)\n",
        "# new_df2 = pd.read_csv(\"your_data.csv\")\n",
        "\n",
        "# Choose the metric you want to analyze (e.g., 'attackVector')\n",
        "selected_metric = 'availabilityImpact'\n",
        "\n",
        "# Calculate class distribution\n",
        "class_counts = df[selected_metric].value_counts()\n",
        "\n",
        "# Calculate the percentage of samples in each class\n",
        "class_percentages = class_counts / class_counts.sum() * 100\n",
        "\n",
        "# Identify imbalanced classes based on a threshold (e.g., 10%)\n",
        "imbalanced_threshold = 10\n",
        "imbalanced_classes = class_percentages[class_percentages < imbalanced_threshold]\n",
        "\n",
        "# Print imbalanced classes\n",
        "print(\"Imbalanced Classes:\")\n",
        "print(imbalanced_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WA5gi00814dV",
        "outputId": "df6b1d43-96ad-40f8-9b0e-22cd777dcefc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imbalanced Classes:\n",
            "LOW    5.59103\n",
            "Name: availabilityImpact, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List of imbalanced classes for each metric\n",
        "imbalanced_classes = {\n",
        "    'attackVector': ['ADJACENT_NETWORK','PHYSICAL'],\n",
        "    'availabilityImpact': ['LOW']\n",
        "}\n",
        "\n",
        "# Filter out rows containing imbalanced classes\n",
        "balanced_data = df[~df.isin(imbalanced_classes).any(axis=1)]"
      ],
      "metadata": {
        "id": "ulOOpcpd14go"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balanced_data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 981
        },
        "id": "3WAa1sYp14jf",
        "outputId": "936772eb-6ff0-44ca-9f84-05571d7bfdea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             descriptions attackVector  \\\n",
              "0       ScriptAlias directory in NCSA and Apache httpd...      NETWORK   \n",
              "1       Cross-site scripting (XSS) vulnerability in th...      NETWORK   \n",
              "2       El protocolo DNS, como es implementado en (1) ...      NETWORK   \n",
              "3       El núcleo de Linux anterior a 2.6.25.10, no re...        LOCAL   \n",
              "4       La función do_change_type en fs/namespace.c de...        LOCAL   \n",
              "...                                                   ...          ...   \n",
              "133409  Errores de lógica empresarial en el repositori...      NETWORK   \n",
              "133410  Falta de autorización en el repositorio de Git...      NETWORK   \n",
              "133411  A vulnerability has been found in UJCMS up to ...      NETWORK   \n",
              "133414  Se ha encontrado una vulnerabilidad en Zhong B...      NETWORK   \n",
              "133426  Cross-site Scripting (XSS) - Stored in GitHub ...      NETWORK   \n",
              "\n",
              "       attackComplexity privilegesRequired userInteraction      scope  \\\n",
              "0                   LOW               NONE            NONE  UNCHANGED   \n",
              "1                   LOW               HIGH        REQUIRED    CHANGED   \n",
              "2                  HIGH               NONE            NONE    CHANGED   \n",
              "3                   LOW                LOW            NONE  UNCHANGED   \n",
              "4                   LOW                LOW            NONE  UNCHANGED   \n",
              "...                 ...                ...             ...        ...   \n",
              "133409              LOW                LOW            NONE  UNCHANGED   \n",
              "133410              LOW                LOW        REQUIRED  UNCHANGED   \n",
              "133411             HIGH                LOW            NONE  UNCHANGED   \n",
              "133414              LOW                LOW            NONE  UNCHANGED   \n",
              "133426              LOW               NONE        REQUIRED  UNCHANGED   \n",
              "\n",
              "       confidentialityImpact integrityImpact availabilityImpact  baseScore  \\\n",
              "0                       HIGH            NONE               NONE        7.5   \n",
              "1                        LOW             LOW               NONE        4.8   \n",
              "2                       NONE            HIGH               NONE        6.8   \n",
              "3                       HIGH            HIGH               HIGH        7.8   \n",
              "4                       HIGH            HIGH               HIGH        7.8   \n",
              "...                      ...             ...                ...        ...   \n",
              "133409                   LOW             LOW               NONE        5.4   \n",
              "133410                   LOW             LOW               NONE        4.6   \n",
              "133411                   LOW            NONE               NONE        3.1   \n",
              "133414                   LOW            NONE               NONE        4.3   \n",
              "133426                   LOW             LOW               HIGH        7.6   \n",
              "\n",
              "       baseSeverity  exploitabilityScore  impactScore  \n",
              "0              HIGH                  3.9          3.6  \n",
              "1            MEDIUM                  1.7          2.7  \n",
              "2            MEDIUM                  2.2          4.0  \n",
              "3              HIGH                  1.8          5.9  \n",
              "4              HIGH                  1.8          5.9  \n",
              "...             ...                  ...          ...  \n",
              "133409       MEDIUM                  2.8          2.5  \n",
              "133410       MEDIUM                  2.1          2.5  \n",
              "133411          LOW                  1.6          1.4  \n",
              "133414       MEDIUM                  2.8          1.4  \n",
              "133426         HIGH                  2.8          4.7  \n",
              "\n",
              "[121466 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ee13e163-f227-4030-9cd1-5bd09845edbe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>descriptions</th>\n",
              "      <th>attackVector</th>\n",
              "      <th>attackComplexity</th>\n",
              "      <th>privilegesRequired</th>\n",
              "      <th>userInteraction</th>\n",
              "      <th>scope</th>\n",
              "      <th>confidentialityImpact</th>\n",
              "      <th>integrityImpact</th>\n",
              "      <th>availabilityImpact</th>\n",
              "      <th>baseScore</th>\n",
              "      <th>baseSeverity</th>\n",
              "      <th>exploitabilityScore</th>\n",
              "      <th>impactScore</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ScriptAlias directory in NCSA and Apache httpd...</td>\n",
              "      <td>NETWORK</td>\n",
              "      <td>LOW</td>\n",
              "      <td>NONE</td>\n",
              "      <td>NONE</td>\n",
              "      <td>UNCHANGED</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>NONE</td>\n",
              "      <td>NONE</td>\n",
              "      <td>7.5</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>3.9</td>\n",
              "      <td>3.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Cross-site scripting (XSS) vulnerability in th...</td>\n",
              "      <td>NETWORK</td>\n",
              "      <td>LOW</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>REQUIRED</td>\n",
              "      <td>CHANGED</td>\n",
              "      <td>LOW</td>\n",
              "      <td>LOW</td>\n",
              "      <td>NONE</td>\n",
              "      <td>4.8</td>\n",
              "      <td>MEDIUM</td>\n",
              "      <td>1.7</td>\n",
              "      <td>2.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>El protocolo DNS, como es implementado en (1) ...</td>\n",
              "      <td>NETWORK</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>NONE</td>\n",
              "      <td>NONE</td>\n",
              "      <td>CHANGED</td>\n",
              "      <td>NONE</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>NONE</td>\n",
              "      <td>6.8</td>\n",
              "      <td>MEDIUM</td>\n",
              "      <td>2.2</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>El núcleo de Linux anterior a 2.6.25.10, no re...</td>\n",
              "      <td>LOCAL</td>\n",
              "      <td>LOW</td>\n",
              "      <td>LOW</td>\n",
              "      <td>NONE</td>\n",
              "      <td>UNCHANGED</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>7.8</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>1.8</td>\n",
              "      <td>5.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>La función do_change_type en fs/namespace.c de...</td>\n",
              "      <td>LOCAL</td>\n",
              "      <td>LOW</td>\n",
              "      <td>LOW</td>\n",
              "      <td>NONE</td>\n",
              "      <td>UNCHANGED</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>7.8</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>1.8</td>\n",
              "      <td>5.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133409</th>\n",
              "      <td>Errores de lógica empresarial en el repositori...</td>\n",
              "      <td>NETWORK</td>\n",
              "      <td>LOW</td>\n",
              "      <td>LOW</td>\n",
              "      <td>NONE</td>\n",
              "      <td>UNCHANGED</td>\n",
              "      <td>LOW</td>\n",
              "      <td>LOW</td>\n",
              "      <td>NONE</td>\n",
              "      <td>5.4</td>\n",
              "      <td>MEDIUM</td>\n",
              "      <td>2.8</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133410</th>\n",
              "      <td>Falta de autorización en el repositorio de Git...</td>\n",
              "      <td>NETWORK</td>\n",
              "      <td>LOW</td>\n",
              "      <td>LOW</td>\n",
              "      <td>REQUIRED</td>\n",
              "      <td>UNCHANGED</td>\n",
              "      <td>LOW</td>\n",
              "      <td>LOW</td>\n",
              "      <td>NONE</td>\n",
              "      <td>4.6</td>\n",
              "      <td>MEDIUM</td>\n",
              "      <td>2.1</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133411</th>\n",
              "      <td>A vulnerability has been found in UJCMS up to ...</td>\n",
              "      <td>NETWORK</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>LOW</td>\n",
              "      <td>NONE</td>\n",
              "      <td>UNCHANGED</td>\n",
              "      <td>LOW</td>\n",
              "      <td>NONE</td>\n",
              "      <td>NONE</td>\n",
              "      <td>3.1</td>\n",
              "      <td>LOW</td>\n",
              "      <td>1.6</td>\n",
              "      <td>1.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133414</th>\n",
              "      <td>Se ha encontrado una vulnerabilidad en Zhong B...</td>\n",
              "      <td>NETWORK</td>\n",
              "      <td>LOW</td>\n",
              "      <td>LOW</td>\n",
              "      <td>NONE</td>\n",
              "      <td>UNCHANGED</td>\n",
              "      <td>LOW</td>\n",
              "      <td>NONE</td>\n",
              "      <td>NONE</td>\n",
              "      <td>4.3</td>\n",
              "      <td>MEDIUM</td>\n",
              "      <td>2.8</td>\n",
              "      <td>1.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133426</th>\n",
              "      <td>Cross-site Scripting (XSS) - Stored in GitHub ...</td>\n",
              "      <td>NETWORK</td>\n",
              "      <td>LOW</td>\n",
              "      <td>NONE</td>\n",
              "      <td>REQUIRED</td>\n",
              "      <td>UNCHANGED</td>\n",
              "      <td>LOW</td>\n",
              "      <td>LOW</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>7.6</td>\n",
              "      <td>HIGH</td>\n",
              "      <td>2.8</td>\n",
              "      <td>4.7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>121466 rows × 13 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee13e163-f227-4030-9cd1-5bd09845edbe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ee13e163-f227-4030-9cd1-5bd09845edbe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ee13e163-f227-4030-9cd1-5bd09845edbe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f0d96a7e-48e2-49a6-9c1e-7492554887fc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f0d96a7e-48e2-49a6-9c1e-7492554887fc')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f0d96a7e-48e2-49a6-9c1e-7492554887fc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List of metrics for which you want to count unique classes\n",
        "metrics_to_count = ['attackVector','attackComplexity','privilegesRequired','userInteraction','scope','confidentialityImpact','integrityImpact','availabilityImpact','baseSeverity']\n",
        "\n",
        "# Count the number of unique classes for each metric and their occurrences\n",
        "for metric in metrics_to_count:\n",
        "    unique_classes =balanced_data[metric].nunique()\n",
        "    class_counts = balanced_data[metric].value_counts()\n",
        "\n",
        "    print(f\"Number of unique classes for {metric}: {unique_classes}\")\n",
        "    print(f\"Class Counts for {metric}:\\n{class_counts}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-H7XBmA14m2",
        "outputId": "44366fb3-75dd-4c15-fdc8-6dbeb15b28b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique classes for attackVector: 2\n",
            "Class Counts for attackVector:\n",
            "NETWORK    91110\n",
            "LOCAL      30356\n",
            "Name: attackVector, dtype: int64\n",
            "Number of unique classes for attackComplexity: 2\n",
            "Class Counts for attackComplexity:\n",
            "LOW     110793\n",
            "HIGH     10673\n",
            "Name: attackComplexity, dtype: int64\n",
            "Number of unique classes for privilegesRequired: 3\n",
            "Class Counts for privilegesRequired:\n",
            "NONE    75963\n",
            "LOW     35350\n",
            "HIGH    10153\n",
            "Name: privilegesRequired, dtype: int64\n",
            "Number of unique classes for userInteraction: 2\n",
            "Class Counts for userInteraction:\n",
            "NONE        76897\n",
            "REQUIRED    44569\n",
            "Name: userInteraction, dtype: int64\n",
            "Number of unique classes for scope: 2\n",
            "Class Counts for scope:\n",
            "UNCHANGED    98629\n",
            "CHANGED      22837\n",
            "Name: scope, dtype: int64\n",
            "Number of unique classes for confidentialityImpact: 3\n",
            "Class Counts for confidentialityImpact:\n",
            "HIGH    70497\n",
            "NONE    26517\n",
            "LOW     24452\n",
            "Name: confidentialityImpact, dtype: int64\n",
            "Number of unique classes for integrityImpact: 3\n",
            "Class Counts for integrityImpact:\n",
            "HIGH    61218\n",
            "NONE    37506\n",
            "LOW     22742\n",
            "Name: integrityImpact, dtype: int64\n",
            "Number of unique classes for availabilityImpact: 2\n",
            "Class Counts for availabilityImpact:\n",
            "HIGH    70934\n",
            "NONE    50532\n",
            "Name: availabilityImpact, dtype: int64\n",
            "Number of unique classes for baseSeverity: 5\n",
            "Class Counts for baseSeverity:\n",
            "HIGH        51245\n",
            "MEDIUM      48194\n",
            "CRITICAL    19023\n",
            "LOW          2994\n",
            "NONE           10\n",
            "Name: baseSeverity, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "wnGSPqo614qS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace 'NONE' with 'LOW' in the 'baseSeverity' column\n",
        "balanced_data['baseSeverity'] = balanced_data['baseSeverity'].replace('NONE', 'LOW')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiHN4TN25DSb",
        "outputId": "b0711b59-c9ea-4742-d85b-3fc65caf86af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-5abda1dc735d>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  balanced_data['baseSeverity'] = balanced_data['baseSeverity'].replace('NONE', 'LOW')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List of metrics for which you want to count unique classes\n",
        "metrics_to_count = ['attackVector','attackComplexity','privilegesRequired','userInteraction','scope','confidentialityImpact','integrityImpact','availabilityImpact','baseSeverity']\n",
        "\n",
        "# Count the number of unique classes for each metric and their occurrences\n",
        "for metric in metrics_to_count:\n",
        "    unique_classes =balanced_data[metric].nunique()\n",
        "    class_counts = balanced_data[metric].value_counts()\n",
        "\n",
        "    print(f\"Number of unique classes for {metric}: {unique_classes}\")\n",
        "    print(f\"Class Counts for {metric}:\\n{class_counts}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zmh2N5Kt5L-A",
        "outputId": "92510e2e-eb3d-481a-c41e-c5cbc9c29f9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique classes for attackVector: 2\n",
            "Class Counts for attackVector:\n",
            "NETWORK    91110\n",
            "LOCAL      30356\n",
            "Name: attackVector, dtype: int64\n",
            "Number of unique classes for attackComplexity: 2\n",
            "Class Counts for attackComplexity:\n",
            "LOW     110793\n",
            "HIGH     10673\n",
            "Name: attackComplexity, dtype: int64\n",
            "Number of unique classes for privilegesRequired: 3\n",
            "Class Counts for privilegesRequired:\n",
            "NONE    75963\n",
            "LOW     35350\n",
            "HIGH    10153\n",
            "Name: privilegesRequired, dtype: int64\n",
            "Number of unique classes for userInteraction: 2\n",
            "Class Counts for userInteraction:\n",
            "NONE        76897\n",
            "REQUIRED    44569\n",
            "Name: userInteraction, dtype: int64\n",
            "Number of unique classes for scope: 2\n",
            "Class Counts for scope:\n",
            "UNCHANGED    98629\n",
            "CHANGED      22837\n",
            "Name: scope, dtype: int64\n",
            "Number of unique classes for confidentialityImpact: 3\n",
            "Class Counts for confidentialityImpact:\n",
            "HIGH    70497\n",
            "NONE    26517\n",
            "LOW     24452\n",
            "Name: confidentialityImpact, dtype: int64\n",
            "Number of unique classes for integrityImpact: 3\n",
            "Class Counts for integrityImpact:\n",
            "HIGH    61218\n",
            "NONE    37506\n",
            "LOW     22742\n",
            "Name: integrityImpact, dtype: int64\n",
            "Number of unique classes for availabilityImpact: 2\n",
            "Class Counts for availabilityImpact:\n",
            "HIGH    70934\n",
            "NONE    50532\n",
            "Name: availabilityImpact, dtype: int64\n",
            "Number of unique classes for baseSeverity: 4\n",
            "Class Counts for baseSeverity:\n",
            "HIGH        51245\n",
            "MEDIUM      48194\n",
            "CRITICAL    19023\n",
            "LOW          3004\n",
            "Name: baseSeverity, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets\n",
        "train_df, test_df = train_test_split(balanced_data, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "urbXd0Jy5gf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the vectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "# Vectorize the vulnerability description\n",
        "X_train = vectorizer.fit_transform(train_df['descriptions'])\n",
        "X_test = vectorizer.transform(test_df['descriptions'])"
      ],
      "metadata": {
        "id": "MyUNG8DP25Ai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics1 = ['attackVector','attackComplexity','privilegesRequired','userInteraction','scope','confidentialityImpact','integrityImpact','availabilityImpact','baseSeverity']\n",
        "\n",
        "mapping_dict = {\n",
        "    'attackVector': {'NETWORK': 1, 'LOCAL':0 },\n",
        "    'attackComplexity': {'LOW': 0 ,'HIGH':1},\n",
        "    'privilegesRequired': {'NONE': 1, 'LOW': 2, 'HIGH': 0},\n",
        "    'userInteraction': {'NONE': 1, 'REQUIRED': 0},\n",
        "    'scope': {'UNCHANGED': 0, 'CHANGED': 1},\n",
        "    'confidentialityImpact': {'NONE': 1, 'LOW': 2, 'HIGH': 0},\n",
        "\n",
        "    'integrityImpact': {'NONE': 1, 'LOW': 2, 'HIGH': 0},\n",
        "    'availabilityImpact': { 'NONE': 1, 'HIGH': 0},\n",
        "    'baseSeverity': {'LOW': 1, 'MEDIUM': 2, 'HIGH': 3, 'CRITICAL':4}\n",
        "}\n",
        "\n",
        "# Assign numerical labels based on the mapping dictionary\n",
        "for metric in metrics1:\n",
        "    train_df[metric] = train_df[metric].map(mapping_dict[metric])\n",
        "    test_df[metric] = test_df[metric].map(mapping_dict[metric])"
      ],
      "metadata": {
        "id": "0BnJOcqE25DK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have already created the mapping_dict and applied label encoding to train_df and test_df\n",
        "\n",
        "for metric in metrics1:\n",
        "    print(f\"Column: {metric}\")\n",
        "    for category, numeric_value in mapping_dict[metric].items():\n",
        "        print(f\"    {category}: {numeric_value}\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82dor_pe25F1",
        "outputId": "a88783ac-9c04-484b-ba16-d8b687b23fca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column: attackVector\n",
            "    NETWORK: 1\n",
            "    LOCAL: 0\n",
            "\n",
            "\n",
            "Column: attackComplexity\n",
            "    LOW: 0\n",
            "    HIGH: 1\n",
            "\n",
            "\n",
            "Column: privilegesRequired\n",
            "    NONE: 1\n",
            "    LOW: 2\n",
            "    HIGH: 0\n",
            "\n",
            "\n",
            "Column: userInteraction\n",
            "    NONE: 1\n",
            "    REQUIRED: 0\n",
            "\n",
            "\n",
            "Column: scope\n",
            "    UNCHANGED: 0\n",
            "    CHANGED: 1\n",
            "\n",
            "\n",
            "Column: confidentialityImpact\n",
            "    NONE: 1\n",
            "    LOW: 2\n",
            "    HIGH: 0\n",
            "\n",
            "\n",
            "Column: integrityImpact\n",
            "    NONE: 1\n",
            "    LOW: 2\n",
            "    HIGH: 0\n",
            "\n",
            "\n",
            "Column: availabilityImpact\n",
            "    NONE: 1\n",
            "    HIGH: 0\n",
            "\n",
            "\n",
            "Column: baseSeverity\n",
            "    LOW: 1\n",
            "    MEDIUM: 2\n",
            "    HIGH: 3\n",
            "    CRITICAL: 4\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the unique values for each metric\n",
        "for metric in metrics1:\n",
        "    unique_values = train_df[metric].unique()\n",
        "    print(f\"Unique values for {metric}: {unique_values}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLRC8zBm25Iy",
        "outputId": "67c3c0cd-0bc1-4225-9af8-3a8d2acb97f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique values for attackVector: [1 0]\n",
            "Unique values for attackComplexity: [0 1]\n",
            "Unique values for privilegesRequired: [1 2 0]\n",
            "Unique values for userInteraction: [1 0]\n",
            "Unique values for scope: [0 1]\n",
            "Unique values for confidentialityImpact: [0 1 2]\n",
            "Unique values for integrityImpact: [1 2 0]\n",
            "Unique values for availabilityImpact: [0 1]\n",
            "Unique values for baseSeverity: [4 2 3 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List of metrics for which you want to count unique classes\n",
        "metrics_to_count = ['attackVector','attackComplexity','privilegesRequired','userInteraction','scope','confidentialityImpact','integrityImpact','availabilityImpact','baseSeverity']\n",
        "\n",
        "# Count the number of unique classes for each metric and their occurrences\n",
        "for metric in metrics_to_count:\n",
        "    unique_classes =train_df[metric].nunique()\n",
        "    class_counts = train_df[metric].value_counts()\n",
        "\n",
        "    print(f\"Number of unique classes for {metric}: {unique_classes}\")\n",
        "    print(f\"Class Counts for {metric}:\\n{class_counts}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2j4QVXqV25Lj",
        "outputId": "6552df9e-c7c7-43f4-920f-d928176d415e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique classes for attackVector: 2\n",
            "Class Counts for attackVector:\n",
            "1    63860\n",
            "0    21166\n",
            "Name: attackVector, dtype: int64\n",
            "Number of unique classes for attackComplexity: 2\n",
            "Class Counts for attackComplexity:\n",
            "0    77510\n",
            "1     7516\n",
            "Name: attackComplexity, dtype: int64\n",
            "Number of unique classes for privilegesRequired: 3\n",
            "Class Counts for privilegesRequired:\n",
            "1    53157\n",
            "2    24776\n",
            "0     7093\n",
            "Name: privilegesRequired, dtype: int64\n",
            "Number of unique classes for userInteraction: 2\n",
            "Class Counts for userInteraction:\n",
            "1    53819\n",
            "0    31207\n",
            "Name: userInteraction, dtype: int64\n",
            "Number of unique classes for scope: 2\n",
            "Class Counts for scope:\n",
            "0    68921\n",
            "1    16105\n",
            "Name: scope, dtype: int64\n",
            "Number of unique classes for confidentialityImpact: 3\n",
            "Class Counts for confidentialityImpact:\n",
            "0    49227\n",
            "1    18612\n",
            "2    17187\n",
            "Name: confidentialityImpact, dtype: int64\n",
            "Number of unique classes for integrityImpact: 3\n",
            "Class Counts for integrityImpact:\n",
            "0    42721\n",
            "1    26330\n",
            "2    15975\n",
            "Name: integrityImpact, dtype: int64\n",
            "Number of unique classes for availabilityImpact: 2\n",
            "Class Counts for availabilityImpact:\n",
            "0    49628\n",
            "1    35398\n",
            "Name: availabilityImpact, dtype: int64\n",
            "Number of unique classes for baseSeverity: 4\n",
            "Class Counts for baseSeverity:\n",
            "3    35731\n",
            "2    33829\n",
            "4    13350\n",
            "1     2116\n",
            "Name: baseSeverity, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = ['attackVector','attackComplexity','privilegesRequired','userInteraction','scope','confidentialityImpact','integrityImpact','availabilityImpact','baseSeverity']\n",
        "\n",
        "# Create a mapping dictionary for CVSS v3 weights\n",
        "weight_mapping = {\n",
        "    'attackVector': {\n",
        "        1: 0.85,\n",
        "        0: 0.5\n",
        "\n",
        "    },\n",
        "    'attackComplexity': {\n",
        "        0: 0.77,\n",
        "        1: 0.44\n",
        "\n",
        "    },\n",
        "    'privilegesRequired': {\n",
        "        1: 0.85,\n",
        "        2: 0.62,\n",
        "        0: 0.27\n",
        "    },\n",
        "    'userInteraction': {\n",
        "        1: 0.85,\n",
        "        0: 0.62\n",
        "    },\n",
        "    'confidentialityImpact': {\n",
        "        0: 0.56,\n",
        "        2: 0.22,\n",
        "        1: 0\n",
        "    },\n",
        "    'integrityImpact': {\n",
        "        0: 0.56,\n",
        "        2: 0.22,\n",
        "        1: 0\n",
        "    },\n",
        "    'availabilityImpact': {\n",
        "        0: 0.56,\n",
        "        1: 0\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "P9yH46vi25OF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import time\n",
        "metrics=['privilegesRequired']\n",
        "\n",
        "# Preprocess the text data\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_df['descriptions'])\n",
        "X_train = tokenizer.texts_to_sequences(train_df['descriptions'])\n",
        "X_train = pad_sequences(X_train)\n",
        "\n",
        "X_test = tokenizer.texts_to_sequences(test_df['descriptions'])\n",
        "X_test = pad_sequences(X_test, maxlen=X_train.shape[1])\n",
        "\n",
        "# Convert categorical labels to numerical using LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "for metric in metrics:\n",
        "    train_df[metric] = label_encoder.fit_transform(train_df[metric])\n",
        "    test_df[metric] = label_encoder.transform(test_df[metric])\n",
        "\n",
        "# Define the CNN model\n",
        "def create_cnn_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=128, input_length=input_shape),\n",
        "        Conv1D(filters=128, kernel_size=5, activation='relu'),\n",
        "        GlobalMaxPooling1D(),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Record the start time\n",
        "start_time = time.time()\n",
        "\n",
        "# Train a CNN model for each metric\n",
        "models = {}\n",
        "for metric in metrics:\n",
        "    num_classes = len(label_encoder.classes_)\n",
        "    model = create_cnn_model(X_train.shape[1], num_classes)\n",
        "    y_train = tf.keras.utils.to_categorical(train_df[metric], num_classes=num_classes)\n",
        "    model.fit(X_train, y_train, epochs=5, batch_size= 64, validation_split=0.2)\n",
        "    models[metric] = model\n",
        "\n",
        "# Record the end time\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate the elapsed time\n",
        "elapsed_time = end_time - start_time\n",
        "\n",
        "# Print the elapsed time\n",
        "print(\"Time taken:\", elapsed_time, \"seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGHBysOT25Qu",
        "outputId": "08a84a3a-930e-42a1-c439-1d243d7b4fdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1063/1063 [==============================] - 655s 616ms/step - loss: 0.5164 - accuracy: 0.7969 - val_loss: 0.4250 - val_accuracy: 0.8381\n",
            "Epoch 2/5\n",
            "1063/1063 [==============================] - 653s 615ms/step - loss: 0.3059 - accuracy: 0.8865 - val_loss: 0.4393 - val_accuracy: 0.8359\n",
            "Epoch 3/5\n",
            "1063/1063 [==============================] - 663s 624ms/step - loss: 0.1569 - accuracy: 0.9475 - val_loss: 0.5141 - val_accuracy: 0.8331\n",
            "Epoch 4/5\n",
            "1063/1063 [==============================] - 668s 629ms/step - loss: 0.0926 - accuracy: 0.9714 - val_loss: 0.5782 - val_accuracy: 0.8324\n",
            "Epoch 5/5\n",
            "1063/1063 [==============================] - 674s 634ms/step - loss: 0.0635 - accuracy: 0.9793 - val_loss: 0.6500 - val_accuracy: 0.8175\n",
            "Time taken: 3314.56396317482 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Initialize a dictionary to store the performance metrics\n",
        "performance_metrics = {}\n",
        "\n",
        "# Iterate through each metric and its corresponding model\n",
        "for metric, model in models.items():\n",
        "    # Make predictions using the trained model\n",
        "    predicted_probabilities = model.predict(X_test)\n",
        "\n",
        "    # Convert continuous probabilities to predicted labels\n",
        "    predicted_labels = np.argmax(predicted_probabilities, axis=1)\n",
        "\n",
        "    # Calculate the accuracy score for the current model\n",
        "    accuracy = accuracy_score(test_df[metric], predicted_labels)\n",
        "\n",
        "    # Calculate other performance metrics (precision, recall, F1-score) using classification_report\n",
        "    report = classification_report(test_df[metric], predicted_labels, output_dict=True)\n",
        "    precision = report['weighted avg']['precision']\n",
        "    recall = report['weighted avg']['recall']\n",
        "    f1_score = report['weighted avg']['f1-score']\n",
        "\n",
        "    # Store the performance metrics in the performance_metrics dictionary\n",
        "    performance_metrics[metric] = {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1_score\n",
        "    }\n",
        "\n",
        "# Print the performance metrics for each model\n",
        "for metric, metrics_dict in performance_metrics.items():\n",
        "    print(f\"Performance metrics for {metric}:\")\n",
        "    print(f\"Accuracy: {metrics_dict['accuracy']}\")\n",
        "    print(f\"Precision: {metrics_dict['precision']}\")\n",
        "    print(f\"Recall: {metrics_dict['recall']}\")\n",
        "    print(f\"F1-score: {metrics_dict['f1_score']}\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EHnWd2I25Ts",
        "outputId": "e5bb445c-2850-41ed-9522-cbefea8b1023"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1139/1139 [==============================] - 76s 66ms/step\n",
            "Performance metrics for privilegesRequired:\n",
            "Accuracy: 0.8160812294182217\n",
            "Precision: 0.8195420542558781\n",
            "Recall: 0.8160812294182217\n",
            "F1-score: 0.8174425868542755\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import joblib\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "if not os.path.exists(\"trained_model\"):\n",
        "    os.makedirs(\"trained_model\")\n",
        "\n",
        "# Save the trained models\n",
        "for metric, model in models.items():\n",
        "    model_filename = f\"trained_model/{metric}_UpdatedCNN.pkl\"\n",
        "    joblib.dump(model, model_filename)"
      ],
      "metadata": {
        "id": "Lerx95Mi-ho0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Load the trained models\n",
        "loaded_models = {}\n",
        "for metric in models.keys():  # Assuming you have a 'models' dictionary\n",
        "    model_filename = f\"trained_model/{metric}_UpdatedCNN.pkl\"\n",
        "    loaded_model = joblib.load(model_filename)\n",
        "    loaded_models[metric] = loaded_model\n",
        "\n",
        "# Now 'loaded_models' dictionary contains the loaded models"
      ],
      "metadata": {
        "id": "NunAPV0c-ky4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Initialize a dictionary to store the performance metrics\n",
        "performance_metrics = {}\n",
        "\n",
        "# Iterate through each metric and its corresponding model\n",
        "for metric, model in loaded_models.items():\n",
        "    # Make predictions using the trained model\n",
        "    predicted_probabilities = model.predict(X_test)\n",
        "\n",
        "    # Convert continuous probabilities to predicted labels\n",
        "    predicted_labels = np.argmax(predicted_probabilities, axis=1)\n",
        "\n",
        "    # Calculate the accuracy score for the current model\n",
        "    accuracy = accuracy_score(test_df[metric], predicted_labels)\n",
        "\n",
        "    # Calculate other performance metrics (precision, recall, F1-score) using classification_report\n",
        "    report = classification_report(test_df[metric], predicted_labels, output_dict=True)\n",
        "    precision = report['weighted avg']['precision']\n",
        "    recall = report['weighted avg']['recall']\n",
        "    f1_score = report['weighted avg']['f1-score']\n",
        "\n",
        "    # Store the performance metrics in the performance_metrics dictionary\n",
        "    performance_metrics[metric] = {\n",
        "        'accuracy': accuracy,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1_score': f1_score\n",
        "    }\n",
        "\n",
        "# Print the performance metrics for each model\n",
        "for metric, metrics_dict in performance_metrics.items():\n",
        "    print(f\"Performance metrics for {metric}:\")\n",
        "    print(f\"Accuracy: {metrics_dict['accuracy']}\")\n",
        "    print(f\"Precision: {metrics_dict['precision']}\")\n",
        "    print(f\"Recall: {metrics_dict['recall']}\")\n",
        "    print(f\"F1-score: {metrics_dict['f1_score']}\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5Jca3Rt25XM",
        "outputId": "9a7be92c-885d-409d-c5d6-1f934959c08e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1139/1139 [==============================] - 73s 64ms/step\n",
            "Performance metrics for privilegesRequired:\n",
            "Accuracy: 0.8160812294182217\n",
            "Precision: 0.8195420542558781\n",
            "Recall: 0.8160812294182217\n",
            "F1-score: 0.8174425868542755\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Initialize the predictions dictionary with empty arrays for each metric\n",
        "predictions = {}\n",
        "\n",
        "# Loop through each metric and its corresponding model\n",
        "for metric, model in models.items():\n",
        "    # Make predictions on the test set for the current metric\n",
        "    predicted_probabilities = model.predict(X_test)\n",
        "    predictions[metric] = predicted_probabilities\n",
        "    # Convert continuous probabilities to predicted labels\n",
        "    predicted_labels = np.argmax(predictions[metric], axis=1)\n",
        "\n",
        "    # Calculate the performance metrics using classification_report\n",
        "    report = classification_report(test_df[metric], predicted_labels, output_dict=True)\n",
        "\n",
        "    # Store the performance metrics in the performance_metrics dictionary\n",
        "    performance_metrics[metric] = {\n",
        "        'accuracy': report['accuracy']\n",
        "    }\n",
        "\n",
        "    # Loop through the classes in the metric and store their precision, recall, and F1-score\n",
        "    for class_label, class_mapping in mapping_dict[metric].items():\n",
        "        class_label = str(class_mapping)  # Convert the class label to string\n",
        "        precision = report[class_label]['precision']\n",
        "        recall = report[class_label]['recall']\n",
        "        f1_score = report[class_label]['f1-score']\n",
        "\n",
        "        performance_metrics[metric][f'class_{class_label}_precision'] = precision\n",
        "        performance_metrics[metric][f'class_{class_label}_recall'] = recall\n",
        "        performance_metrics[metric][f'class_{class_label}_f1_score'] = f1_score\n",
        "\n",
        "# Print the performance metrics for each model and class within each metric\n",
        "for metric, metrics_dict in performance_metrics.items():\n",
        "    print(f\"Performance metrics for {metric}:\")\n",
        "    print(f\"Accuracy: {metrics_dict['accuracy']}\")\n",
        "    for class_label, class_mapping in mapping_dict[metric].items():\n",
        "        class_label = str(class_mapping)  # Convert the class label to string\n",
        "        print(f\"Class {class_label} Precision: {metrics_dict[f'class_{class_label}_precision']}\")\n",
        "        print(f\"Class {class_label} Recall: {metrics_dict[f'class_{class_label}_recall']}\")\n",
        "        print(f\"Class {class_label} F1-score: {metrics_dict[f'class_{class_label}_f1_score']}\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KIKNH2jFEO3",
        "outputId": "c4957960-dbf7-49b2-e43e-b9a708f7d2b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1139/1139 [==============================] - 72s 63ms/step\n",
            "Performance metrics for privilegesRequired:\n",
            "Accuracy: 0.8160812294182217\n",
            "Class 1 Precision: 0.8917304123478025\n",
            "Class 1 Recall: 0.8638516179952644\n",
            "Class 1 F1-score: 0.8775696563397849\n",
            "Class 2 Precision: 0.7144628465149234\n",
            "Class 2 Recall: 0.7629090221297522\n",
            "Class 2 F1-score: 0.7378916075920421\n",
            "Class 0 Precision: 0.6446335078534031\n",
            "Class 0 Recall: 0.6437908496732027\n",
            "Class 0 F1-score: 0.6442119032047091\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the severity mapping dictionary\n",
        "severity_mapping = {'LOW': 1, 'MEDIUM': 3, 'HIGH': 0, 'CRITICAL': 4, 'NONE': 2}\n",
        "Reverse_severity_mapping = {1: 'LOW', 3: 'MEDIUM', 0: 'HIGH', 4: 'CRITICAL', 2: 'NONE'}\n",
        "\n",
        "# Calculate ISC_Base (Impact Sub Score Base)\n",
        "def calculate_ISC(row):\n",
        "    ISC_Base = 1 - (\n",
        "        (1 - weight_mapping['confidentialityImpact'].get(row['confidentialityImpact'])) *\n",
        "        (1 - weight_mapping['integrityImpact'].get(row['integrityImpact'])) *\n",
        "        (1 - weight_mapping['availabilityImpact'].get(row['availabilityImpact']))\n",
        "    )\n",
        "\n",
        "\n",
        "    if row['scope'] == 0:  # Scope Unchanged\n",
        "        return 6.42 * ISC_Base\n",
        "    else:  # Scope Changed\n",
        "        return 7.52 * (ISC_Base - 0.029) - 3.25 * (ISC_Base - 0.02) ** 15\n",
        "\n",
        "# Initialize a list to store calculated base severities\n",
        "calculated_base_severities = []\n",
        "calculated_base_scores = []\n",
        "\n",
        "# Iterate through each data point's predictions\n",
        "for i in range(X_test.shape[0]):  # Use shape[0] to get the number of rows\n",
        "    # Extract predicted values for each metric from the predictions dictionary\n",
        "    predicted_metrics = [predictions[metric][i] for metric in metrics]\n",
        "\n",
        "    # Calculate ISC using the provided formula and predicted metrics\n",
        "    isc = calculate_ISC(test_df.iloc[i])  # Use your existing calculate_ISC function\n",
        "\n",
        "    # Calculate ESS (Exploitability Sub Score) using the provided formula and weights\n",
        "    ess = (\n",
        "        8.22 * weight_mapping['attackVector'].get(predicted_metrics[0]) *\n",
        "        weight_mapping['attackComplexity'].get(predicted_metrics[1]) *\n",
        "        weight_mapping['privilegesRequired'].get(predicted_metrics[2]) *\n",
        "        weight_mapping['userInteraction'].get(predicted_metrics[3])\n",
        "    )\n",
        "\n",
        "    # Calculate the Base Score using the provided formula\n",
        "    #if predicted_metrics[4] == 0:  # Scope Unchanged\n",
        "       # isc_base = 6.42 * isc\n",
        "    #else:  # Scope Changed\n",
        "        #isc_base = 7.52 * (isc - 0.029) - 3.25 * (isc - 0.02) ** 15\n",
        "\n",
        "    if isc <= 0:\n",
        "        base_score = 0\n",
        "    elif predicted_metrics[4] == 0:  # Scope Unchanged\n",
        "        base_score = min(isc + ess, 10)\n",
        "    else:  # Scope Changed\n",
        "        base_score = min(1.08 * (isc + ess), 10)\n",
        "\n",
        "    # Round off the base score to one decimal place\n",
        "    rounded_base_score = round(base_score, 1)\n",
        "\n",
        "    # Append to the list\n",
        "    calculated_base_scores.append(rounded_base_score)\n",
        "\n",
        "\n",
        "    # Assign base severity based on the calculated base score\n",
        "\n",
        "    if base_score <= 3.9:\n",
        "        base_severity = 'LOW'\n",
        "    elif base_score <= 6.9:\n",
        "        base_severity = 'MEDIUM'\n",
        "    elif base_score <= 8.9:\n",
        "        base_severity = 'HIGH'\n",
        "    else:\n",
        "        base_severity = 'CRITICAL'\n",
        "\n",
        "    calculated_base_severities.append(base_severity)\n",
        "\n",
        "# Assign the calculated base severities to the DataFrame\n",
        "test_df['calculated_base_severity'] = calculated_base_severities\n",
        "# Assign the calculated base scores as a new column in the DataFrame\n",
        "test_df['calculated_base_score'] = calculated_base_scores\n",
        "\n",
        "# Print the DataFrame to see the calculated base severities\n",
        "print(test_df[['calculated_base_severity']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5r4Zb5a8awX",
        "outputId": "191e1efb-91ff-4813-acc7-b983ce25bdb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       calculated_base_severity\n",
            "85218                      HIGH\n",
            "57228                    MEDIUM\n",
            "101816                   MEDIUM\n",
            "20321                      HIGH\n",
            "72997                    MEDIUM\n",
            "...                         ...\n",
            "87654                    MEDIUM\n",
            "70650                      HIGH\n",
            "45012                  CRITICAL\n",
            "112917                     HIGH\n",
            "122175                     HIGH\n",
            "\n",
            "[36440 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the severity mapping\n",
        "severity_mapping = {'LOW': 1, 'MEDIUM': 2, 'HIGH': 3, 'CRITICAL': 4 }\n",
        "# Initialize a variable to count correct predictions\n",
        "correct_predictions = 0\n",
        "\n",
        "# Iterate through each data point's predictions\n",
        "for i, row in test_df.iterrows():\n",
        "    predicted_severity_label = row['calculated_base_severity']\n",
        "    actual_severity_numeric = row['baseSeverity']\n",
        "\n",
        "    # Convert predicted label to numeric using the mapping\n",
        "    predicted_severity_numeric = severity_mapping.get(predicted_severity_label, -1)  # -1 if label not found\n",
        "\n",
        "    if predicted_severity_numeric == actual_severity_numeric:\n",
        "        correct_predictions += 1\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = (correct_predictions / test_df.shape[0]) * 100\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmmLyrd_8a8I",
        "outputId": "30a7ad86-45f9-4880-99af-2b87f82349d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 72.01%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Convert true baseSeverity values to numerical values\n",
        "test_df['calculated_base_severityLabel'] = test_df['calculated_base_severity'].map(severity_mapping)\n",
        "true_base_severity_numerical = test_df['baseSeverity']\n",
        "predicted_base_severity_numerical=test_df['calculated_base_severityLabel']\n",
        "\n",
        "# Calculate precision, recall, and F1-score overall\n",
        "precision = precision_score(true_base_severity_numerical, predicted_base_severity_numerical, average='weighted')\n",
        "recall = recall_score(true_base_severity_numerical, predicted_base_severity_numerical, average='weighted')\n",
        "f1 = f1_score(true_base_severity_numerical, predicted_base_severity_numerical, average='weighted')\n",
        "\n",
        "# Print overall precision, recall, and F1-score\n",
        "print(\"Overall Metrics:\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-score: {f1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lU9Ej9518a_q",
        "outputId": "bdb1867a-da4d-45ff-b498-65842c5a55a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall Metrics:\n",
            "Precision: 0.7645122692232816\n",
            "Recall: 0.7201152579582876\n",
            "F1-score: 0.7244187687961569\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Convert true baseSeverity values to numerical values\n",
        "test_df['calculated_base_severityLabel'] = test_df['calculated_base_severity'].map(severity_mapping)\n",
        "true_base_severity_numerical = test_df['baseSeverity']\n",
        "predicted_base_severity_numerical=test_df['calculated_base_severityLabel']\n",
        "\n",
        "# Calculate accuracy for each class separately\n",
        "class_labels = [1,2, 3, 4]  # Numeric values corresponding to 'LOW', 'MEDIUM', and 'HIGH'\n",
        "accuracy_scores = {}\n",
        "\n",
        "for class_label in class_labels:\n",
        "    class_pred = [1 if pred_class == class_label else 0 for pred_class in predicted_base_severity_numerical]\n",
        "\n",
        "    class_accuracy = accuracy_score(true_base_severity_numerical == class_label, class_pred)\n",
        "    accuracy_scores[class_label] = class_accuracy\n",
        "\n",
        "# Print accuracy scores for each class\n",
        "for class_label, accuracy in accuracy_scores.items():\n",
        "    print(f\"Accuracy for class {class_label}: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zc3jTKn-9sVf",
        "outputId": "417dbec6-95ae-4b64-ce48-9734a79b0fd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for class 1: 0.980159165751921\n",
            "Accuracy for class 2: 0.8628704720087815\n",
            "Accuracy for class 3: 0.7482711306256861\n",
            "Accuracy for class 4: 0.8489297475301866\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the counts of each value in 'baseSeverity' and 'bSeverity' columns\n",
        "base_severity_counts = test_df['baseSeverity'].value_counts()\n",
        "b_severity_counts = test_df['calculated_base_severity'].value_counts()\n",
        "\n",
        "# Print the counts of each value in both columns side by side for comparison\n",
        "print(\"Value Counts:\")\n",
        "print(f\"{'baseSeverity':<15}{'calculated_base_severity':<15}\")\n",
        "print(\"-\" * 30)\n",
        "for base_severity, b_severity in zip(base_severity_counts.index, b_severity_counts.index):\n",
        "    print(f\"{str(base_severity):<15}{str(b_severity):<15}\")\n",
        "\n",
        "# Print the counts of each value in 'baseSeverity' column\n",
        "print(\"\\nCount of each value in 'baseSeverity' column:\")\n",
        "for base_severity, count in base_severity_counts.items():\n",
        "    print(f\"{base_severity}: {count}\")\n",
        "\n",
        "# Print the counts of each value in 'calculated_base_severity' column\n",
        "print(\"\\nCount of each value in 'calculated_base_severity' column:\")\n",
        "for b_severity, count in b_severity_counts.items():\n",
        "    print(f\"{b_severity}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39uI1BUA90-E",
        "outputId": "6dfa23aa-83ae-4570-d596-870706eb77d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Value Counts:\n",
            "baseSeverity   calculated_base_severity\n",
            "------------------------------\n",
            "3              HIGH           \n",
            "2              MEDIUM         \n",
            "4              CRITICAL       \n",
            "1              LOW            \n",
            "\n",
            "Count of each value in 'baseSeverity' column:\n",
            "3: 15514\n",
            "2: 14365\n",
            "4: 5673\n",
            "1: 888\n",
            "\n",
            "Count of each value in 'calculated_base_severity' column:\n",
            "HIGH: 14551\n",
            "MEDIUM: 11348\n",
            "CRITICAL: 10282\n",
            "LOW: 259\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Compute the confusion matrix\n",
        "conf_matrix = confusion_matrix(true_base_severity_numerical, predicted_base_severity_numerical)\n",
        "\n",
        "# Calculate TP, TN, FP, and FN for each class\n",
        "class_labels = [1, 2, 3, 4]\n",
        "metrics_by_class = {}\n",
        "\n",
        "for class_label in class_labels:\n",
        "    class_idx = class_label - 1\n",
        "    TP = conf_matrix[class_idx, class_idx]\n",
        "    FN = sum(conf_matrix[class_idx, :]) - TP\n",
        "    FP = sum(conf_matrix[:, class_idx]) - TP\n",
        "    TN = conf_matrix.sum() - (TP + FN + FP)\n",
        "\n",
        "    metrics_by_class[class_label] = {'TP': TP, 'TN': TN, 'FP': FP, 'FN': FN}\n",
        "\n",
        "# Print the metrics for each class\n",
        "for class_label, metrics in metrics_by_class.items():\n",
        "    print(f\"Class {class_label}:\")\n",
        "    print(f\"True Positives: {metrics['TP']}\")\n",
        "    print(f\"True Negatives: {metrics['TN']}\")\n",
        "    print(f\"False Positives: {metrics['FP']}\")\n",
        "    print(f\"False Negatives: {metrics['FN']}\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUSAWtOW91BT",
        "outputId": "0347e82d-6095-4878-cfc9-01f7291c7cde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 1:\n",
            "True Positives: 212\n",
            "True Negatives: 35505\n",
            "False Positives: 47\n",
            "False Negatives: 676\n",
            "\n",
            "\n",
            "Class 2:\n",
            "True Positives: 10358\n",
            "True Negatives: 21085\n",
            "False Positives: 990\n",
            "False Negatives: 4007\n",
            "\n",
            "\n",
            "Class 3:\n",
            "True Positives: 10446\n",
            "True Negatives: 16821\n",
            "False Positives: 4105\n",
            "False Negatives: 5068\n",
            "\n",
            "\n",
            "Class 4:\n",
            "True Positives: 5225\n",
            "True Negatives: 25710\n",
            "False Positives: 5057\n",
            "False Negatives: 448\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Convert true baseSeverity values to numerical values\n",
        "test_df['calculated_base_severityLabel'] = test_df['calculated_base_severity'].map(severity_mapping)\n",
        "true_base_severity_numerical = test_df['baseSeverity']\n",
        "predicted_base_severity_numerical=test_df['calculated_base_severityLabel']\n",
        "\n",
        "# Calculate precision, recall, and F1-score for each class separately\n",
        "precision_scores = {}\n",
        "recall_scores = {}\n",
        "f1_scores = {}\n",
        "\n",
        "for class_label in class_labels:\n",
        "    class_pred = [1 if pred_class == class_label else 0 for pred_class in predicted_base_severity_numerical]\n",
        "\n",
        "    precision = precision_score(true_base_severity_numerical == class_label, class_pred)\n",
        "    recall = recall_score(true_base_severity_numerical == class_label, class_pred)\n",
        "    f1 = f1_score(true_base_severity_numerical == class_label, class_pred)\n",
        "\n",
        "    precision_scores[class_label] = precision\n",
        "    recall_scores[class_label] = recall\n",
        "    f1_scores[class_label] = f1\n",
        "\n",
        "# Print precision, recall, and F1-score for each class\n",
        "for class_label in class_labels:\n",
        "    print(f\"Class {class_label}:\")\n",
        "    print(f\"Precision: {precision_scores[class_label]}\")\n",
        "    print(f\"Recall: {recall_scores[class_label]}\")\n",
        "    print(f\"F1-score: {f1_scores[class_label]}\")\n",
        "    print(\"\\n\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RCg8WST91Es",
        "outputId": "e04c4b62-2578-4e87-8cbd-421731cfdd34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 1:\n",
            "Precision: 0.8185328185328186\n",
            "Recall: 0.23873873873873874\n",
            "F1-score: 0.3696599825632083\n",
            "\n",
            "\n",
            "Class 2:\n",
            "Precision: 0.9127599577017976\n",
            "Recall: 0.721058127392969\n",
            "F1-score: 0.8056625053474896\n",
            "\n",
            "\n",
            "Class 3:\n",
            "Precision: 0.7178888048931344\n",
            "Recall: 0.673327317261828\n",
            "F1-score: 0.6948943954764676\n",
            "\n",
            "\n",
            "Class 4:\n",
            "Precision: 0.5081696168060689\n",
            "Recall: 0.9210294376872906\n",
            "F1-score: 0.6549670949545596\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}